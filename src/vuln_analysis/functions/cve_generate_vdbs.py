# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import logging
import os
import time
from pathlib import Path

from nat.builder.builder import Builder
from nat.builder.framework_enum import LLMFrameworkEnum
from nat.builder.function_info import FunctionInfo
from nat.cli.register_workflow import register_function
from nat.data_models.component_ref import FunctionRef
from nat.data_models.function import FunctionBaseConfig
from pydantic import Field

from vuln_analysis.utils.error_utils import API_KEY_SETUP_LINK
from vuln_analysis.utils.error_utils import is_authentication_error

logger = logging.getLogger(__name__)


class CVEGenerateVDBsToolConfig(FunctionBaseConfig, name="cve_generate_vdbs"):
    """
    Defines a function that generates a vector database from code repositories and documentation.
    """
    agent_name: FunctionRef = Field(
        description=
        "Name of the agent executor. Used to determine which tools are enabled in the agent to conditionally generate "
        "vector databases or indexes.")
    embedder_name: str = Field(description="Name of embedder to use.")
    base_git_dir: str = Field(default=".cache/am_cache/git",
                              description="The directory for storing pulled git repositories used for code analysis.")
    base_vdb_dir: str = Field(default=".cache/am_cache/vdb",
                              description="The directory used for storing vector database files.")
    base_code_index_dir: str = Field(default=".cache/am_cache/code_index",
                                     description="The directory used for storing code index files.")
    ignore_errors: bool = Field(default=False, description="Whether to ignore errors during generation.")
    ignore_code_embedding: bool = Field(default=False, description="Whether to ignore building code vector database.")
    ignore_doc_embedding: bool = Field(default=False,
                                       description="Whether to ignore building documentation vector database.")
    ignore_code_index: bool = Field(default=False, description="Whether to ignore building code index.")


@register_function(config_type=CVEGenerateVDBsToolConfig, framework_wrappers=[LLMFrameworkEnum.LANGCHAIN])
async def generate_vdb(config: CVEGenerateVDBsToolConfig, builder: Builder):

    from vuln_analysis.data_models.info import AgentMorpheusInfo
    from vuln_analysis.data_models.input import AgentMorpheusEngineInput
    from vuln_analysis.data_models.input import AgentMorpheusInput
    from vuln_analysis.data_models.input import SourceDocumentsInfo
    from vuln_analysis.functions.cve_agent import CVEAgentExecutorToolConfig
    from vuln_analysis.utils.document_embedding import DocumentEmbedding
    from vuln_analysis.utils.full_text_search import FullTextSearch
    from vuln_analysis.utils.git_utils import get_repo_from_path

    agent_config = builder.get_function_config(config.agent_name)
    assert isinstance(agent_config, CVEAgentExecutorToolConfig)

    # Update config based on tools available in agent config
    if "Container Image Code QA System" not in agent_config.tool_names:
        logger.info("Container Image Code QA System tool is not enabled, setting ignore_code_embedding to True")
        config.ignore_code_embedding = True

    if "Container Image Developer Guide QA System" not in agent_config.tool_names:
        logger.info(
            "Container Image Developer Guide QA System tool is not enabled, setting ignore_doc_embedding to True")
        config.ignore_doc_embedding = True

    if "Lexical Search Container Image Code QA System" not in agent_config.tool_names:
        logger.info(
            "Lexical Search Container Image Code QA System tool is not enabled, setting ignore_code_index to True")
        config.ignore_code_index = True

    embedding = await builder.get_embedder(embedder_name=config.embedder_name, wrapper_type=LLMFrameworkEnum.LANGCHAIN)

    embedder = DocumentEmbedding(embedding=embedding,
                                 vdb_directory=config.base_vdb_dir,
                                 git_directory=config.base_git_dir)

    def _create_code_index(source_infos: list[SourceDocumentsInfo], embedder: DocumentEmbedding, output_path: Path):
        logger.info("Collecting documents from git repos. Source Infos: %s",
                    json.dumps([x.model_dump(mode="json") for x in source_infos]))

        output_path = Path(output_path)

        # Warn if the output path already exists and we will overwrite it
        if (output_path.exists()):
            logger.warning("Code index already exists and will be overwritten: %s", output_path)

        documents = []
        for si in source_infos:
            try:
                documents.extend(embedder.collect_documents(si))
            except Exception as e:
                logger.warning("Error collecting documents for source info %s: %s", si, e)
                continue

        # Warn and return early if no documents were collected
        if len(documents) == 0:
            logger.warning("No documents were collected, skipping code indexing for source infos: '%s'", source_infos)
            return None

        # Apply chunking on the source documents
        chunked_documents = embedder._chunk_documents(documents)

        logger.info("Creating code index from source documents. Doc count: %d, Chunks: %s, Location: %s",
                    len(documents),
                    len(chunked_documents),
                    output_path)

        full_text_search = FullTextSearch(cache_path=str(output_path))
        indexing_start_time = time.time()
        full_text_search.add_documents_from_langchain_chunks(chunked_documents)
        logger.info("Completed code indexing in %.2f seconds for '%s'", time.time() - indexing_start_time, output_path)

        return full_text_search

    def _build_code_index(source_infos: list[SourceDocumentsInfo]) -> Path | None:
        code_index_path: Path | None = None

        # Filter to only code sources
        source_infos = [si for si in source_infos if si.type == 'code']

        if source_infos:

            # Use DocumentEmbedding class with embedding=None for its utility functions
            embedder = DocumentEmbedding(embedding=None)

            # Determine code index path for either loading from cache or creating new index
            # Need to add support for configurable base path
            code_index_path = FullTextSearch.get_index_directory(
                base_path=config.base_code_index_dir, hash_value=embedder.hash_source_documents_info(source_infos))

            if (not code_index_path.exists() or os.environ.get("MORPHEUS_ALWAYS_REBUILD_VDB", "0") == "1"):
                index = _create_code_index(source_infos, embedder, code_index_path)

                # Return None if the index was not created
                if index is None:
                    code_index_path = None
            else:
                logger.info("Cache hit on code index. Loading existing code index: %s", code_index_path)

        return code_index_path

    async def _arun(message: AgentMorpheusInput) -> AgentMorpheusEngineInput:
        """
        Builds source code and documentation FAISS databases based upon the source repositories.
        For now we are only storing a path to the FAISS databases in the message.

        In the future we will want to store the actual FAISS databases in the message.

        Parameters
        ----------
        message : AgentMorpheusInput
            The input message
        build_vdb_fn : typing.Callable[[str, str, list[SourceCodeRepo]], dict[str, str]]
            The function that builds the VDB database for a given vulnerability scan id, base image, and source code
            repos
        ignore_errors : bool
            When True raised exceptions will be logged, when False raised exceptions will be re-raised
        """
        workflow_config = builder.get_workflow_config()

        vdb_code_path = None
        vdb_doc_path = None
        code_index_path = None

        base_image = message.image.name
        source_infos = message.image.source_info

        try:

            # Build VDBs
            vdb_code_path, vdb_doc_path = embedder.build_vdbs(
                source_infos, config.ignore_code_embedding, config.ignore_doc_embedding)

            if (vdb_code_path is None):
                # Only log warning if we're not ignoring code embeddings
                if (not config.ignore_code_embedding):
                    logger.warning(("Failed to generate code VDB for image '%s'. "
                                    "Ensure the source repositories are setup correctly"),
                                   base_image)

            if (vdb_doc_path is None):
                # Only log warning if we're not ignoring doc embeddings
                if (not config.ignore_doc_embedding):
                    logger.warning(("Failed to generate documentation VDB for image '%s'. "
                                    "Ensure the source repositories are setup correctly"),
                                   base_image)

            # Build code index if not ignored
            if (not config.ignore_code_index):
                code_index_path = _build_code_index(source_infos)

                if code_index_path is None:
                    logger.warning(("Failed to generate code index for image '%s'. "
                                    "Ensure the source repositories are setup correctly"),
                                   base_image)

            # Replace ref with specific commit hash for each source info
            for si in source_infos:
                try:
                    repo = get_repo_from_path(config.base_git_dir, si.git_repo)
                    si.ref = repo.commit().hexsha
                except ValueError as e:
                    logger.warning("Failed to get commit hash for %s/%s: %s", config.base_git_dir, si.git_repo, e)
                    continue

        except Exception as e:
            # Check if this is an authentication/authorization error
            # These don't require stack traces as they're typically API key issues
            is_auth_error = is_authentication_error(e)

            if is_auth_error:
                logger.error(
                    "Failure to build VDB for image, '%s', with source code info: %s\n"
                    "Error: %s\n"
                    "This appears to be an authentication error. Please check your API key configuration.\n"
                    "See %s for instructions on obtaining API keys.",
                    base_image,
                    source_infos,
                    e,
                    API_KEY_SETUP_LINK)
            else:
                logger.error("Failure to build VDB for image, '%s', with source code info: %s\nError: %s",
                             base_image,
                             source_infos,
                             e,
                             exc_info=True)

            if not config.ignore_errors:
                raise

            logger.warning("Ignoring VDB generation error and continuing with missing VDBs.")

        # Handle missing_source_action configuration
        vdbs_generated = any([vdb_code_path, vdb_doc_path, code_index_path])

        if not vdbs_generated:
            if workflow_config.missing_source_action == "error":  # type: ignore
                raise RuntimeError(
                    "No VDBs were built and the workflow's missing_source_action is set to 'error'. "
                    f"To allow empty VDBs, change the setting to 'skip_agent' or 'continue_with_warning'. "
                    f"Image: {base_image}, Source info: {source_infos}")

            logger.warning(
                "No VDBs were built but continuing due to workflow's missing_source_action setting ('%s'). "
                "Image: %s, Source info: %s",
                workflow_config.missing_source_action,  # type: ignore
                base_image,
                source_infos)

        vdb_code_path = str(vdb_code_path) if vdb_code_path is not None else None
        vdb_doc_path = str(vdb_doc_path) if vdb_doc_path is not None else None
        code_index_path = str(code_index_path) if code_index_path is not None else None

        info = AgentMorpheusInfo(vdb=AgentMorpheusInfo.VdbPaths(
            code_vdb_path=vdb_code_path, doc_vdb_path=vdb_doc_path, code_index_path=code_index_path))

        return AgentMorpheusEngineInput(input=message, info=info)

    yield FunctionInfo.from_fn(_arun,
                               input_schema=AgentMorpheusInput,
                               description=("Generates vector database from code repositories and documentation."))
